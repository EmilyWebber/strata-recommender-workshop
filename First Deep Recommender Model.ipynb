{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import Sequential\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns_to_embed(df):\n",
    "    df['docs_to_embed'] = ''\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        new_str = '{}, {}, {}'.format(row['product_title'], row['review_headline'], row['review_body'])\n",
    "        df.loc[idx, 'docs_to_embed'] = new_str\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def read_data(f_name):\n",
    "    data = []\n",
    "    count = 0\n",
    "    with open(f_name) as f:\n",
    "        for row in f.readlines():\n",
    "            data.append(row.strip('\\n').split('\\t'))\n",
    "#             count += 1\n",
    "#             print (count)\n",
    "#             if count > 100:\n",
    "#                 print ('tripped the if statement!')\n",
    "#                 break\n",
    "                \n",
    "    df = pd.DataFrame(data[1:], columns = data[0])\n",
    "    \n",
    "    df.drop(['marketplace', 'review_id', 'product_parent'], axis=1, inplace=True)\n",
    "    df = combine_columns_to_embed(df)\n",
    " \n",
    "    return df\n",
    "\n",
    "# need some help on figuring out why this takes forever to run\n",
    "# df = read_data('amazon_reviews_us_Books_v1_00.tsv')\n",
    "\n",
    "\n",
    "df = read_data('sample_us.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id          object\n",
       "product_id           object\n",
       "product_title        object\n",
       "product_category     object\n",
       "star_rating          object\n",
       "helpful_votes        object\n",
       "total_votes          object\n",
       "vine                 object\n",
       "verified_purchase    object\n",
       "review_headline      object\n",
       "review_body          object\n",
       "review_date          object\n",
       "docs_to_embed        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_embeddings = ['product_title', 'review_headline', 'review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_without_embeddings = ['customer_id', 'product_id', 'product_category', 'votes', 'vine', 'verified_purchase', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe consider date a running variable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df):\n",
    "    labels = [1 if int(x) >= 4 else 0 for x in df['star_rating'] ]\n",
    "    return labels\n",
    "\n",
    "labels = get_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a model\n",
    "\n",
    "### Features to embed:\n",
    "1. Product title\n",
    "2. Review headline\n",
    "3. Review body\n",
    "4. Customer ID\n",
    "5. Product ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_ids(df, id_name):\n",
    "\n",
    "    assert id_name in ['customer_id', 'product_id', 'docs_to_embed']\n",
    "    \n",
    "    vocab_size = get_vocab_size(df, col_name = id_name)\n",
    "\n",
    "    docs = df[id_name].values.tolist()\n",
    "    \n",
    "    encoded_ids = [one_hot(d, vocab_size) for d in docs]\n",
    "\n",
    "    return np.array(encoded_ids)\n",
    "\n",
    "def get_vocab_size(df, col_name):\n",
    "    vocab_size = len(set((' ').join(df[col_name]).split()))\n",
    "    return vocab_size\n",
    "\n",
    "def get_max_length(df, col_name):\n",
    "    max_length = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        doc = row[col_name]\n",
    "        l = len(doc.split())\n",
    "        if l > max_length:\n",
    "            max_length = l\n",
    "            \n",
    "    return max_length\n",
    "\n",
    "def get_padded_documents(df):\n",
    "    encoded_docs = get_encoded_ids(df, 'docs_to_embed')\n",
    "    max_length = get_max_length(df, 'docs_to_embed')\n",
    "    \n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "    return padded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional inputs\n",
    "On top of looking at the textual data, we have a few additional columns we need to consider. Each of these we'll consider a running variable\n",
    "1. Product category\n",
    "2. Votes\n",
    "\n",
    "In the tiny sample dataset, all the records are on the same date and are in the same product category, so there's no reason to include either date or product category in the first model. We'll specify all of these as  inputs, then pass them in as a list to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29\n",
       "1    14\n",
       "2     3\n",
       "4     2\n",
       "6     1\n",
       "Name: total_votes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_votes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_input_specs(df):\n",
    "    vocab_size = get_vocab_size(df, 'docs_to_embed')\n",
    "    max_length = get_max_length(df, col_name = 'docs_to_embed')\n",
    "\n",
    "    n_users = len(set(df['customer_id'].values.tolist()))\n",
    "    n_products = len(set(df['product_id'].values.tolist()))\n",
    "\n",
    "    return vocab_size, max_length, n_users, n_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    vocab_size, max_length, n_users, n_products = get_model_input_specs(df)\n",
    "\n",
    "    votes_input = Input(shape=[1,], name=\"Votes-Input\")    \n",
    "    \n",
    "    doc_input = Input(shape=[max_length,], name=\"Document-Input\")\n",
    "    doc_embedding = Embedding(vocab_size, 8, name=\"Document-Embedding\", input_length=max_length)(doc_input)\n",
    "    doc_vec = Flatten(name=\"Flatten-Documents\")(doc_embedding)\n",
    "\n",
    "    product_input = Input(shape=[1], name=\"Product-Input\")\n",
    "    product_embedding = Embedding(n_products+1, 5, name=\"Product-Embedding\")(product_input)\n",
    "    product_vec = Flatten(name=\"Flatten-Products\")(product_embedding)\n",
    "\n",
    "    user_input = Input(shape=[1], name=\"User-Input\")\n",
    "    user_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
    "\n",
    "    user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "    prod = Dot(name=\"Dot-Product\", axes=1)([product_vec, user_vec])\n",
    "\n",
    "    # your model is a list of embedded inputs, then the dot product, then the scaled running variables \n",
    "    model = Model([user_input, product_input, doc_input, votes_input], prod)\n",
    "\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled(df, col_name):\n",
    "    x = [int(x) for x in df[col_name]]\n",
    "    \n",
    "    x = np.reshape(x, (-1, 1))\n",
    "\n",
    "    scaler_x = MinMaxScaler()\n",
    "\n",
    "    scaler_x.fit(x)\n",
    "    \n",
    "    xscale = scaler_x.transform(x)\n",
    "\n",
    "    return xscale\n",
    "\n",
    "def get_model_input_data(df):\n",
    "    \n",
    "    padded_docs = get_padded_documents(df)\n",
    "    \n",
    "    encoded_product_ids = get_encoded_ids(df, 'product_id')\n",
    "    \n",
    "    encoded_customer_idx = get_encoded_ids(df, 'customer_id')\n",
    "\n",
    "    votes = get_scaled(df, 'total_votes')\n",
    "    \n",
    "    return [encoded_customer_idx, encoded_product_ids, padded_docs, votes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39 samples, validate on 10 samples\n",
      "Epoch 1/500\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 18.7188 - val_loss: 21.7050\n",
      "Epoch 2/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 18.7166 - val_loss: 21.7048\n",
      "Epoch 3/500\n",
      "39/39 [==============================] - 0s 75us/step - loss: 18.7144 - val_loss: 21.7045\n",
      "Epoch 4/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 18.7122 - val_loss: 21.7042\n",
      "Epoch 5/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 18.7099 - val_loss: 21.7039\n",
      "Epoch 6/500\n",
      "39/39 [==============================] - 0s 77us/step - loss: 18.7078 - val_loss: 21.7035\n",
      "Epoch 7/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 18.7056 - val_loss: 21.7031\n",
      "Epoch 8/500\n",
      "39/39 [==============================] - 0s 76us/step - loss: 18.7034 - val_loss: 21.7026\n",
      "Epoch 9/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 18.7012 - val_loss: 21.7021\n",
      "Epoch 10/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 18.6990 - val_loss: 21.7016\n",
      "Epoch 11/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.6968 - val_loss: 21.7010\n",
      "Epoch 12/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 18.6945 - val_loss: 21.7005\n",
      "Epoch 13/500\n",
      "39/39 [==============================] - 0s 110us/step - loss: 18.6921 - val_loss: 21.7000\n",
      "Epoch 14/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 18.6898 - val_loss: 21.6995\n",
      "Epoch 15/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 18.6873 - val_loss: 21.6990\n",
      "Epoch 16/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 18.6848 - val_loss: 21.6985\n",
      "Epoch 17/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.6822 - val_loss: 21.6980\n",
      "Epoch 18/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 18.6795 - val_loss: 21.6975\n",
      "Epoch 19/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 18.6767 - val_loss: 21.6970\n",
      "Epoch 20/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.6737 - val_loss: 21.6965\n",
      "Epoch 21/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 18.6707 - val_loss: 21.6960\n",
      "Epoch 22/500\n",
      "39/39 [==============================] - 0s 82us/step - loss: 18.6676 - val_loss: 21.6954\n",
      "Epoch 23/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.6641 - val_loss: 21.6948\n",
      "Epoch 24/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 18.6608 - val_loss: 21.6942\n",
      "Epoch 25/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.6573 - val_loss: 21.6936\n",
      "Epoch 26/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 18.6536 - val_loss: 21.6930\n",
      "Epoch 27/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.6498 - val_loss: 21.6923\n",
      "Epoch 28/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 18.6459 - val_loss: 21.6917\n",
      "Epoch 29/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 18.6415 - val_loss: 21.6911\n",
      "Epoch 30/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.6372 - val_loss: 21.6905\n",
      "Epoch 31/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 18.6326 - val_loss: 21.6898\n",
      "Epoch 32/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 18.6276 - val_loss: 21.6892\n",
      "Epoch 33/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 18.6229 - val_loss: 21.6885\n",
      "Epoch 34/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 18.6176 - val_loss: 21.6879\n",
      "Epoch 35/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 18.6122 - val_loss: 21.6872\n",
      "Epoch 36/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 18.6067 - val_loss: 21.6865\n",
      "Epoch 37/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 18.6009 - val_loss: 21.6858\n",
      "Epoch 38/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 18.5949 - val_loss: 21.6852\n",
      "Epoch 39/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 18.5887 - val_loss: 21.6844\n",
      "Epoch 40/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 18.5823 - val_loss: 21.6836\n",
      "Epoch 41/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 18.5758 - val_loss: 21.6828\n",
      "Epoch 42/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 18.5688 - val_loss: 21.6821\n",
      "Epoch 43/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.5615 - val_loss: 21.6813\n",
      "Epoch 44/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.5545 - val_loss: 21.6805\n",
      "Epoch 45/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 18.5469 - val_loss: 21.6797\n",
      "Epoch 46/500\n",
      "39/39 [==============================] - 0s 82us/step - loss: 18.5392 - val_loss: 21.6790\n",
      "Epoch 47/500\n",
      "39/39 [==============================] - 0s 81us/step - loss: 18.5313 - val_loss: 21.6782\n",
      "Epoch 48/500\n",
      "39/39 [==============================] - 0s 82us/step - loss: 18.5229 - val_loss: 21.6774\n",
      "Epoch 49/500\n",
      "39/39 [==============================] - 0s 80us/step - loss: 18.5144 - val_loss: 21.6766\n",
      "Epoch 50/500\n",
      "39/39 [==============================] - 0s 105us/step - loss: 18.5056 - val_loss: 21.6759\n",
      "Epoch 51/500\n",
      "39/39 [==============================] - 0s 105us/step - loss: 18.4968 - val_loss: 21.6749\n",
      "Epoch 52/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 18.4871 - val_loss: 21.6740\n",
      "Epoch 53/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 18.4779 - val_loss: 21.6732\n",
      "Epoch 54/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.4677 - val_loss: 21.6724\n",
      "Epoch 55/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 18.4578 - val_loss: 21.6716\n",
      "Epoch 56/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.4474 - val_loss: 21.6708\n",
      "Epoch 57/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 18.4366 - val_loss: 21.6700\n",
      "Epoch 58/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 18.4259 - val_loss: 21.6692\n",
      "Epoch 59/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 18.4144 - val_loss: 21.6685\n",
      "Epoch 60/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.4032 - val_loss: 21.6678\n",
      "Epoch 61/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 18.3915 - val_loss: 21.6670\n",
      "Epoch 62/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 18.3790 - val_loss: 21.6662\n",
      "Epoch 63/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.3667 - val_loss: 21.6654\n",
      "Epoch 64/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.3541 - val_loss: 21.6645\n",
      "Epoch 65/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 18.3411 - val_loss: 21.6637\n",
      "Epoch 66/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 18.3279 - val_loss: 21.6629\n",
      "Epoch 67/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.3143 - val_loss: 21.6622\n",
      "Epoch 68/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 18.3003 - val_loss: 21.6614\n",
      "Epoch 69/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 18.2860 - val_loss: 21.6605\n",
      "Epoch 70/500\n",
      "39/39 [==============================] - 0s 106us/step - loss: 18.2713 - val_loss: 21.6596\n",
      "Epoch 71/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.2564 - val_loss: 21.6588\n",
      "Epoch 72/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 18.2411 - val_loss: 21.6581\n",
      "Epoch 73/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 18.2258 - val_loss: 21.6575\n",
      "Epoch 74/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 18.2095 - val_loss: 21.6569\n",
      "Epoch 75/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 18.1936 - val_loss: 21.6564\n",
      "Epoch 76/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.1769 - val_loss: 21.6558\n",
      "Epoch 77/500\n",
      "39/39 [==============================] - 0s 82us/step - loss: 18.1599 - val_loss: 21.6552\n",
      "Epoch 78/500\n",
      "39/39 [==============================] - 0s 82us/step - loss: 18.1427 - val_loss: 21.6545\n",
      "Epoch 79/500\n",
      "39/39 [==============================] - 0s 82us/step - loss: 18.1254 - val_loss: 21.6539\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 103us/step - loss: 18.1073 - val_loss: 21.6534\n",
      "Epoch 81/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 18.0895 - val_loss: 21.6530\n",
      "Epoch 82/500\n",
      "39/39 [==============================] - 0s 105us/step - loss: 18.0708 - val_loss: 21.6525\n",
      "Epoch 83/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 18.0520 - val_loss: 21.6520\n",
      "Epoch 84/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 18.0331 - val_loss: 21.6514\n",
      "Epoch 85/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 18.0141 - val_loss: 21.6507\n",
      "Epoch 86/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 17.9951 - val_loss: 21.6500\n",
      "Epoch 87/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 17.9745 - val_loss: 21.6494\n",
      "Epoch 88/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 17.9553 - val_loss: 21.6491\n",
      "Epoch 89/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 17.9343 - val_loss: 21.6490\n",
      "Epoch 90/500\n",
      "39/39 [==============================] - 0s 113us/step - loss: 17.9136 - val_loss: 21.6488\n",
      "Epoch 91/500\n",
      "39/39 [==============================] - 0s 115us/step - loss: 17.8929 - val_loss: 21.6486\n",
      "Epoch 92/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 17.8718 - val_loss: 21.6485\n",
      "Epoch 93/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 17.8498 - val_loss: 21.6483\n",
      "Epoch 94/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 17.8282 - val_loss: 21.6481\n",
      "Epoch 95/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 17.8056 - val_loss: 21.6481\n",
      "Epoch 96/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 17.7833 - val_loss: 21.6480\n",
      "Epoch 97/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 17.7601 - val_loss: 21.6480\n",
      "Epoch 98/500\n",
      "39/39 [==============================] - 0s 105us/step - loss: 17.7365 - val_loss: 21.6481\n",
      "Epoch 99/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 17.7138 - val_loss: 21.6482\n",
      "Epoch 100/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 17.6893 - val_loss: 21.6482\n",
      "Epoch 101/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 17.6650 - val_loss: 21.6484\n",
      "Epoch 102/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 17.6419 - val_loss: 21.6485\n",
      "Epoch 103/500\n",
      "39/39 [==============================] - 0s 79us/step - loss: 17.6168 - val_loss: 21.6484\n",
      "Epoch 104/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 17.5918 - val_loss: 21.6484\n",
      "Epoch 105/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 17.5677 - val_loss: 21.6486\n",
      "Epoch 106/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 17.5421 - val_loss: 21.6487\n",
      "Epoch 107/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 17.5172 - val_loss: 21.6487\n",
      "Epoch 108/500\n",
      "39/39 [==============================] - 0s 79us/step - loss: 17.4907 - val_loss: 21.6487\n",
      "Epoch 109/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 17.4664 - val_loss: 21.6487\n",
      "Epoch 110/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 17.4393 - val_loss: 21.6486\n",
      "Epoch 111/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 17.4131 - val_loss: 21.6485\n",
      "Epoch 112/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 17.3863 - val_loss: 21.6484\n",
      "Epoch 113/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 17.3589 - val_loss: 21.6481\n",
      "Epoch 114/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 17.3322 - val_loss: 21.6477\n",
      "Epoch 115/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 17.3036 - val_loss: 21.6473\n",
      "Epoch 116/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 17.2756 - val_loss: 21.6467\n",
      "Epoch 117/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 17.2470 - val_loss: 21.6464\n",
      "Epoch 118/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 17.2183 - val_loss: 21.6463\n",
      "Epoch 119/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 17.1882 - val_loss: 21.6462\n",
      "Epoch 120/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 17.1590 - val_loss: 21.6459\n",
      "Epoch 121/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 17.1293 - val_loss: 21.6454\n",
      "Epoch 122/500\n",
      "39/39 [==============================] - 0s 106us/step - loss: 17.0980 - val_loss: 21.6450\n",
      "Epoch 123/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 17.0677 - val_loss: 21.6446\n",
      "Epoch 124/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 17.0365 - val_loss: 21.6443\n",
      "Epoch 125/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 17.0059 - val_loss: 21.6441\n",
      "Epoch 126/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 16.9739 - val_loss: 21.6440\n",
      "Epoch 127/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 16.9422 - val_loss: 21.6441\n",
      "Epoch 128/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 16.9101 - val_loss: 21.6445\n",
      "Epoch 129/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 16.8785 - val_loss: 21.6448\n",
      "Epoch 130/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 16.8462 - val_loss: 21.6451\n",
      "Epoch 131/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 16.8134 - val_loss: 21.6452\n",
      "Epoch 132/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 16.7803 - val_loss: 21.6452\n",
      "Epoch 133/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 16.7463 - val_loss: 21.6451\n",
      "Epoch 134/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 16.7135 - val_loss: 21.6448\n",
      "Epoch 135/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 16.6794 - val_loss: 21.6446\n",
      "Epoch 136/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 16.6456 - val_loss: 21.6445\n",
      "Epoch 137/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 16.6117 - val_loss: 21.6443\n",
      "Epoch 138/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 16.5777 - val_loss: 21.6442\n",
      "Epoch 139/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 16.5435 - val_loss: 21.6443\n",
      "Epoch 140/500\n",
      "39/39 [==============================] - 0s 106us/step - loss: 16.5083 - val_loss: 21.6441\n",
      "Epoch 141/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 16.4733 - val_loss: 21.6437\n",
      "Epoch 142/500\n",
      "39/39 [==============================] - 0s 75us/step - loss: 16.4383 - val_loss: 21.6433\n",
      "Epoch 143/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 16.4027 - val_loss: 21.6429\n",
      "Epoch 144/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 16.3666 - val_loss: 21.6427\n",
      "Epoch 145/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 16.3310 - val_loss: 21.6423\n",
      "Epoch 146/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 16.2934 - val_loss: 21.6420\n",
      "Epoch 147/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 16.2574 - val_loss: 21.6418\n",
      "Epoch 148/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 16.2212 - val_loss: 21.6416\n",
      "Epoch 149/500\n",
      "39/39 [==============================] - 0s 78us/step - loss: 16.1838 - val_loss: 21.6415\n",
      "Epoch 150/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 16.1460 - val_loss: 21.6416\n",
      "Epoch 151/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 16.1086 - val_loss: 21.6417\n",
      "Epoch 152/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 16.0718 - val_loss: 21.6418\n",
      "Epoch 153/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 16.0325 - val_loss: 21.6418\n",
      "Epoch 154/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 15.9946 - val_loss: 21.6418\n",
      "Epoch 155/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 15.9558 - val_loss: 21.6418\n",
      "Epoch 156/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 15.9171 - val_loss: 21.6417\n",
      "Epoch 157/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 15.8787 - val_loss: 21.6415\n",
      "Epoch 158/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 15.8394 - val_loss: 21.6414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 15.8015 - val_loss: 21.6414\n",
      "Epoch 160/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 15.7613 - val_loss: 21.6415\n",
      "Epoch 161/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 15.7223 - val_loss: 21.6418\n",
      "Epoch 162/500\n",
      "39/39 [==============================] - 0s 125us/step - loss: 15.6836 - val_loss: 21.6421\n",
      "Epoch 163/500\n",
      "39/39 [==============================] - 0s 122us/step - loss: 15.6443 - val_loss: 21.6426\n",
      "Epoch 164/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 15.6057 - val_loss: 21.6429\n",
      "Epoch 165/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 15.5651 - val_loss: 21.6435\n",
      "Epoch 166/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 15.5254 - val_loss: 21.6446\n",
      "Epoch 167/500\n",
      "39/39 [==============================] - 0s 74us/step - loss: 15.4856 - val_loss: 21.6456\n",
      "Epoch 168/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 15.4461 - val_loss: 21.6463\n",
      "Epoch 169/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 15.4045 - val_loss: 21.6468\n",
      "Epoch 170/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 15.3645 - val_loss: 21.6474\n",
      "Epoch 171/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 15.3226 - val_loss: 21.6477\n",
      "Epoch 172/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 15.2830 - val_loss: 21.6479\n",
      "Epoch 173/500\n",
      "39/39 [==============================] - 0s 80us/step - loss: 15.2422 - val_loss: 21.6483\n",
      "Epoch 174/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 15.2007 - val_loss: 21.6486\n",
      "Epoch 175/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 15.1611 - val_loss: 21.6488\n",
      "Epoch 176/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 15.1195 - val_loss: 21.6489\n",
      "Epoch 177/500\n",
      "39/39 [==============================] - 0s 82us/step - loss: 15.0789 - val_loss: 21.6491\n",
      "Epoch 178/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 15.0365 - val_loss: 21.6496\n",
      "Epoch 179/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 14.9950 - val_loss: 21.6500\n",
      "Epoch 180/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 14.9525 - val_loss: 21.6502\n",
      "Epoch 181/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 14.9104 - val_loss: 21.6502\n",
      "Epoch 182/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 14.8671 - val_loss: 21.6499\n",
      "Epoch 183/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 14.8245 - val_loss: 21.6495\n",
      "Epoch 184/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 14.7823 - val_loss: 21.6494\n",
      "Epoch 185/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 14.7379 - val_loss: 21.6496\n",
      "Epoch 186/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 14.6959 - val_loss: 21.6495\n",
      "Epoch 187/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 14.6519 - val_loss: 21.6496\n",
      "Epoch 188/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 14.6076 - val_loss: 21.6499\n",
      "Epoch 189/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 14.5628 - val_loss: 21.6500\n",
      "Epoch 190/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 14.5193 - val_loss: 21.6499\n",
      "Epoch 191/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 14.4750 - val_loss: 21.6498\n",
      "Epoch 192/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 14.4318 - val_loss: 21.6498\n",
      "Epoch 193/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 14.3875 - val_loss: 21.6494\n",
      "Epoch 194/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 14.3442 - val_loss: 21.6489\n",
      "Epoch 195/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 14.2998 - val_loss: 21.6484\n",
      "Epoch 196/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 14.2555 - val_loss: 21.6479\n",
      "Epoch 197/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 14.2111 - val_loss: 21.6474\n",
      "Epoch 198/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 14.1667 - val_loss: 21.6468\n",
      "Epoch 199/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 14.1232 - val_loss: 21.6461\n",
      "Epoch 200/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 14.0788 - val_loss: 21.6454\n",
      "Epoch 201/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 14.0334 - val_loss: 21.6446\n",
      "Epoch 202/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 13.9890 - val_loss: 21.6441\n",
      "Epoch 203/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 13.9433 - val_loss: 21.6438\n",
      "Epoch 204/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 13.8965 - val_loss: 21.6438\n",
      "Epoch 205/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 13.8519 - val_loss: 21.6442\n",
      "Epoch 206/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 13.8051 - val_loss: 21.6450\n",
      "Epoch 207/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 13.7588 - val_loss: 21.6461\n",
      "Epoch 208/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 13.7116 - val_loss: 21.6472\n",
      "Epoch 209/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 13.6653 - val_loss: 21.6481\n",
      "Epoch 210/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 13.6211 - val_loss: 21.6487\n",
      "Epoch 211/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 13.5742 - val_loss: 21.6493\n",
      "Epoch 212/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 13.5275 - val_loss: 21.6500\n",
      "Epoch 213/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 13.4817 - val_loss: 21.6509\n",
      "Epoch 214/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 13.4360 - val_loss: 21.6517\n",
      "Epoch 215/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 13.3906 - val_loss: 21.6522\n",
      "Epoch 216/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 13.3452 - val_loss: 21.6527\n",
      "Epoch 217/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 13.2981 - val_loss: 21.6533\n",
      "Epoch 218/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 13.2534 - val_loss: 21.6542\n",
      "Epoch 219/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 13.2062 - val_loss: 21.6549\n",
      "Epoch 220/500\n",
      "39/39 [==============================] - 0s 123us/step - loss: 13.1606 - val_loss: 21.6553\n",
      "Epoch 221/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 13.1137 - val_loss: 21.6559\n",
      "Epoch 222/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 13.0676 - val_loss: 21.6567\n",
      "Epoch 223/500\n",
      "39/39 [==============================] - 0s 108us/step - loss: 13.0208 - val_loss: 21.6574\n",
      "Epoch 224/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 12.9734 - val_loss: 21.6581\n",
      "Epoch 225/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 12.9289 - val_loss: 21.6585\n",
      "Epoch 226/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 12.8805 - val_loss: 21.6589\n",
      "Epoch 227/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 12.8347 - val_loss: 21.6591\n",
      "Epoch 228/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 12.7877 - val_loss: 21.6594\n",
      "Epoch 229/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 12.7403 - val_loss: 21.6599\n",
      "Epoch 230/500\n",
      "39/39 [==============================] - 0s 74us/step - loss: 12.6938 - val_loss: 21.6607\n",
      "Epoch 231/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 12.6449 - val_loss: 21.6618\n",
      "Epoch 232/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 12.5964 - val_loss: 21.6627\n",
      "Epoch 233/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 12.5482 - val_loss: 21.6637\n",
      "Epoch 234/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 12.5009 - val_loss: 21.6650\n",
      "Epoch 235/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 12.4521 - val_loss: 21.6662\n",
      "Epoch 236/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 12.4042 - val_loss: 21.6676\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 79us/step - loss: 12.3550 - val_loss: 21.6690\n",
      "Epoch 238/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 12.3070 - val_loss: 21.6706\n",
      "Epoch 239/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 12.2577 - val_loss: 21.6722\n",
      "Epoch 240/500\n",
      "39/39 [==============================] - 0s 112us/step - loss: 12.2096 - val_loss: 21.6740\n",
      "Epoch 241/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 12.1602 - val_loss: 21.6757\n",
      "Epoch 242/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 12.1105 - val_loss: 21.6774\n",
      "Epoch 243/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 12.0625 - val_loss: 21.6792\n",
      "Epoch 244/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 12.0139 - val_loss: 21.6815\n",
      "Epoch 245/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 11.9641 - val_loss: 21.6837\n",
      "Epoch 246/500\n",
      "39/39 [==============================] - 0s 80us/step - loss: 11.9158 - val_loss: 21.6858\n",
      "Epoch 247/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 11.8661 - val_loss: 21.6878\n",
      "Epoch 248/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 11.8160 - val_loss: 21.6900\n",
      "Epoch 249/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 11.7651 - val_loss: 21.6916\n",
      "Epoch 250/500\n",
      "39/39 [==============================] - 0s 110us/step - loss: 11.7152 - val_loss: 21.6928\n",
      "Epoch 251/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 11.6657 - val_loss: 21.6941\n",
      "Epoch 252/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 11.6139 - val_loss: 21.6960\n",
      "Epoch 253/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 11.5631 - val_loss: 21.6989\n",
      "Epoch 254/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 11.5125 - val_loss: 21.7023\n",
      "Epoch 255/500\n",
      "39/39 [==============================] - 0s 79us/step - loss: 11.4629 - val_loss: 21.7052\n",
      "Epoch 256/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 11.4115 - val_loss: 21.7073\n",
      "Epoch 257/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 11.3617 - val_loss: 21.7090\n",
      "Epoch 258/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 11.3102 - val_loss: 21.7102\n",
      "Epoch 259/500\n",
      "39/39 [==============================] - 0s 80us/step - loss: 11.2604 - val_loss: 21.7111\n",
      "Epoch 260/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 11.2100 - val_loss: 21.7118\n",
      "Epoch 261/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 11.1606 - val_loss: 21.7123\n",
      "Epoch 262/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 11.1131 - val_loss: 21.7129\n",
      "Epoch 263/500\n",
      "39/39 [==============================] - 0s 105us/step - loss: 11.0619 - val_loss: 21.7135\n",
      "Epoch 264/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 11.0136 - val_loss: 21.7140\n",
      "Epoch 265/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 10.9648 - val_loss: 21.7144\n",
      "Epoch 266/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 10.9162 - val_loss: 21.7148\n",
      "Epoch 267/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 10.8673 - val_loss: 21.7152\n",
      "Epoch 268/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 10.8184 - val_loss: 21.7157\n",
      "Epoch 269/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 10.7702 - val_loss: 21.7163\n",
      "Epoch 270/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 10.7212 - val_loss: 21.7172\n",
      "Epoch 271/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 10.6743 - val_loss: 21.7184\n",
      "Epoch 272/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 10.6253 - val_loss: 21.7196\n",
      "Epoch 273/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 10.5787 - val_loss: 21.7206\n",
      "Epoch 274/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 10.5295 - val_loss: 21.7214\n",
      "Epoch 275/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 10.4828 - val_loss: 21.7221\n",
      "Epoch 276/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 10.4320 - val_loss: 21.7226\n",
      "Epoch 277/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 10.3845 - val_loss: 21.7237\n",
      "Epoch 278/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 10.3342 - val_loss: 21.7250\n",
      "Epoch 279/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 10.2857 - val_loss: 21.7265\n",
      "Epoch 280/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 10.2370 - val_loss: 21.7286\n",
      "Epoch 281/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 10.1868 - val_loss: 21.7306\n",
      "Epoch 282/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 10.1387 - val_loss: 21.7321\n",
      "Epoch 283/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 10.0887 - val_loss: 21.7334\n",
      "Epoch 284/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 10.0416 - val_loss: 21.7350\n",
      "Epoch 285/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 9.9920 - val_loss: 21.7367\n",
      "Epoch 286/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 9.9428 - val_loss: 21.7381\n",
      "Epoch 287/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 9.8957 - val_loss: 21.7397\n",
      "Epoch 288/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 9.8467 - val_loss: 21.7408\n",
      "Epoch 289/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 9.8000 - val_loss: 21.7415\n",
      "Epoch 290/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 9.7527 - val_loss: 21.7425\n",
      "Epoch 291/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 9.7048 - val_loss: 21.7445\n",
      "Epoch 292/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 9.6583 - val_loss: 21.7466\n",
      "Epoch 293/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 9.6117 - val_loss: 21.7485\n",
      "Epoch 294/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 9.5650 - val_loss: 21.7507\n",
      "Epoch 295/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 9.5198 - val_loss: 21.7529\n",
      "Epoch 296/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 9.4723 - val_loss: 21.7547\n",
      "Epoch 297/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 9.4263 - val_loss: 21.7561\n",
      "Epoch 298/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 9.3782 - val_loss: 21.7571\n",
      "Epoch 299/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 9.3317 - val_loss: 21.7578\n",
      "Epoch 300/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 9.2830 - val_loss: 21.7589\n",
      "Epoch 301/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 9.2371 - val_loss: 21.7606\n",
      "Epoch 302/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 9.1881 - val_loss: 21.7623\n",
      "Epoch 303/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 9.1412 - val_loss: 21.7635\n",
      "Epoch 304/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 9.0923 - val_loss: 21.7647\n",
      "Epoch 305/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 9.0469 - val_loss: 21.7662\n",
      "Epoch 306/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 8.9995 - val_loss: 21.7675\n",
      "Epoch 307/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 8.9528 - val_loss: 21.7687\n",
      "Epoch 308/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 8.9068 - val_loss: 21.7694\n",
      "Epoch 309/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 8.8627 - val_loss: 21.7698\n",
      "Epoch 310/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 8.8183 - val_loss: 21.7700\n",
      "Epoch 311/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 8.7714 - val_loss: 21.7701\n",
      "Epoch 312/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 8.7270 - val_loss: 21.7705\n",
      "Epoch 313/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 8.6809 - val_loss: 21.7713\n",
      "Epoch 314/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 8.6338 - val_loss: 21.7724\n",
      "Epoch 315/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 8.5903 - val_loss: 21.7738\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 99us/step - loss: 8.5425 - val_loss: 21.7747\n",
      "Epoch 317/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 8.4959 - val_loss: 21.7753\n",
      "Epoch 318/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 8.4501 - val_loss: 21.7756\n",
      "Epoch 319/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 8.4037 - val_loss: 21.7756\n",
      "Epoch 320/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 8.3570 - val_loss: 21.7758\n",
      "Epoch 321/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 8.3114 - val_loss: 21.7765\n",
      "Epoch 322/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 8.2634 - val_loss: 21.7771\n",
      "Epoch 323/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 8.2184 - val_loss: 21.7776\n",
      "Epoch 324/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 8.1711 - val_loss: 21.7781\n",
      "Epoch 325/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 8.1263 - val_loss: 21.7789\n",
      "Epoch 326/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 8.0797 - val_loss: 21.7797\n",
      "Epoch 327/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 8.0334 - val_loss: 21.7804\n",
      "Epoch 328/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 7.9886 - val_loss: 21.7811\n",
      "Epoch 329/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 7.9432 - val_loss: 21.7820\n",
      "Epoch 330/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 7.8985 - val_loss: 21.7836\n",
      "Epoch 331/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 7.8529 - val_loss: 21.7851\n",
      "Epoch 332/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 7.8096 - val_loss: 21.7864\n",
      "Epoch 333/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 7.7647 - val_loss: 21.7875\n",
      "Epoch 334/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 7.7218 - val_loss: 21.7888\n",
      "Epoch 335/500\n",
      "39/39 [==============================] - 0s 105us/step - loss: 7.6768 - val_loss: 21.7905\n",
      "Epoch 336/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 7.6329 - val_loss: 21.7919\n",
      "Epoch 337/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 7.5894 - val_loss: 21.7935\n",
      "Epoch 338/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 7.5451 - val_loss: 21.7958\n",
      "Epoch 339/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 7.5001 - val_loss: 21.7985\n",
      "Epoch 340/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 7.4565 - val_loss: 21.8012\n",
      "Epoch 341/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 7.4127 - val_loss: 21.8035\n",
      "Epoch 342/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 7.3684 - val_loss: 21.8055\n",
      "Epoch 343/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 7.3250 - val_loss: 21.8071\n",
      "Epoch 344/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 7.2801 - val_loss: 21.8082\n",
      "Epoch 345/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 7.2372 - val_loss: 21.8088\n",
      "Epoch 346/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 7.1932 - val_loss: 21.8091\n",
      "Epoch 347/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 7.1506 - val_loss: 21.8095\n",
      "Epoch 348/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 7.1074 - val_loss: 21.8100\n",
      "Epoch 349/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 7.0652 - val_loss: 21.8109\n",
      "Epoch 350/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 7.0243 - val_loss: 21.8124\n",
      "Epoch 351/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 6.9808 - val_loss: 21.8140\n",
      "Epoch 352/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 6.9396 - val_loss: 21.8158\n",
      "Epoch 353/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 6.8978 - val_loss: 21.8172\n",
      "Epoch 354/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 6.8561 - val_loss: 21.8190\n",
      "Epoch 355/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 6.8149 - val_loss: 21.8215\n",
      "Epoch 356/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 6.7740 - val_loss: 21.8235\n",
      "Epoch 357/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 6.7323 - val_loss: 21.8256\n",
      "Epoch 358/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 6.6912 - val_loss: 21.8279\n",
      "Epoch 359/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 6.6492 - val_loss: 21.8297\n",
      "Epoch 360/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 6.6081 - val_loss: 21.8311\n",
      "Epoch 361/500\n",
      "39/39 [==============================] - 0s 108us/step - loss: 6.5659 - val_loss: 21.8322\n",
      "Epoch 362/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 6.5244 - val_loss: 21.8330\n",
      "Epoch 363/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 6.4830 - val_loss: 21.8337\n",
      "Epoch 364/500\n",
      "39/39 [==============================] - 0s 79us/step - loss: 6.4423 - val_loss: 21.8349\n",
      "Epoch 365/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 6.4016 - val_loss: 21.8370\n",
      "Epoch 366/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 6.3609 - val_loss: 21.8393\n",
      "Epoch 367/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 6.3203 - val_loss: 21.8413\n",
      "Epoch 368/500\n",
      "39/39 [==============================] - 0s 111us/step - loss: 6.2795 - val_loss: 21.8429\n",
      "Epoch 369/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 6.2381 - val_loss: 21.8442\n",
      "Epoch 370/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 6.1971 - val_loss: 21.8457\n",
      "Epoch 371/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 6.1581 - val_loss: 21.8476\n",
      "Epoch 372/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 6.1158 - val_loss: 21.8492\n",
      "Epoch 373/500\n",
      "39/39 [==============================] - 0s 105us/step - loss: 6.0763 - val_loss: 21.8504\n",
      "Epoch 374/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 6.0356 - val_loss: 21.8512\n",
      "Epoch 375/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 5.9949 - val_loss: 21.8522\n",
      "Epoch 376/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 5.9547 - val_loss: 21.8531\n",
      "Epoch 377/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 5.9151 - val_loss: 21.8541\n",
      "Epoch 378/500\n",
      "39/39 [==============================] - 0s 108us/step - loss: 5.8747 - val_loss: 21.8556\n",
      "Epoch 379/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 5.8347 - val_loss: 21.8569\n",
      "Epoch 380/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 5.7963 - val_loss: 21.8580\n",
      "Epoch 381/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 5.7553 - val_loss: 21.8587\n",
      "Epoch 382/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 5.7173 - val_loss: 21.8590\n",
      "Epoch 383/500\n",
      "39/39 [==============================] - 0s 109us/step - loss: 5.6762 - val_loss: 21.8598\n",
      "Epoch 384/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 5.6374 - val_loss: 21.8614\n",
      "Epoch 385/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 5.5980 - val_loss: 21.8632\n",
      "Epoch 386/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 5.5579 - val_loss: 21.8658\n",
      "Epoch 387/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 5.5208 - val_loss: 21.8685\n",
      "Epoch 388/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 5.4816 - val_loss: 21.8707\n",
      "Epoch 389/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 5.4435 - val_loss: 21.8723\n",
      "Epoch 390/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 5.4062 - val_loss: 21.8734\n",
      "Epoch 391/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 5.3685 - val_loss: 21.8750\n",
      "Epoch 392/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 5.3326 - val_loss: 21.8777\n",
      "Epoch 393/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 5.2967 - val_loss: 21.8802\n",
      "Epoch 394/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 5.2604 - val_loss: 21.8824\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 94us/step - loss: 5.2255 - val_loss: 21.8848\n",
      "Epoch 396/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 5.1910 - val_loss: 21.8876\n",
      "Epoch 397/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 5.1549 - val_loss: 21.8902\n",
      "Epoch 398/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 5.1212 - val_loss: 21.8930\n",
      "Epoch 399/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 5.0856 - val_loss: 21.8959\n",
      "Epoch 400/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 5.0513 - val_loss: 21.8990\n",
      "Epoch 401/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 5.0153 - val_loss: 21.9022\n",
      "Epoch 402/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 4.9812 - val_loss: 21.9058\n",
      "Epoch 403/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 4.9469 - val_loss: 21.9093\n",
      "Epoch 404/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 4.9119 - val_loss: 21.9122\n",
      "Epoch 405/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 4.8782 - val_loss: 21.9146\n",
      "Epoch 406/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 4.8434 - val_loss: 21.9165\n",
      "Epoch 407/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 4.8098 - val_loss: 21.9177\n",
      "Epoch 408/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 4.7747 - val_loss: 21.9184\n",
      "Epoch 409/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 4.7417 - val_loss: 21.9191\n",
      "Epoch 410/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 4.7076 - val_loss: 21.9202\n",
      "Epoch 411/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 4.6728 - val_loss: 21.9219\n",
      "Epoch 412/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 4.6393 - val_loss: 21.9236\n",
      "Epoch 413/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 4.6058 - val_loss: 21.9256\n",
      "Epoch 414/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 4.5712 - val_loss: 21.9274\n",
      "Epoch 415/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 4.5381 - val_loss: 21.9296\n",
      "Epoch 416/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 4.5061 - val_loss: 21.9321\n",
      "Epoch 417/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 4.4726 - val_loss: 21.9342\n",
      "Epoch 418/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 4.4403 - val_loss: 21.9362\n",
      "Epoch 419/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 4.4082 - val_loss: 21.9380\n",
      "Epoch 420/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 4.3751 - val_loss: 21.9409\n",
      "Epoch 421/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 4.3427 - val_loss: 21.9444\n",
      "Epoch 422/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 4.3098 - val_loss: 21.9470\n",
      "Epoch 423/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 4.2784 - val_loss: 21.9490\n",
      "Epoch 424/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 4.2460 - val_loss: 21.9509\n",
      "Epoch 425/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 4.2148 - val_loss: 21.9530\n",
      "Epoch 426/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 4.1824 - val_loss: 21.9547\n",
      "Epoch 427/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 4.1509 - val_loss: 21.9568\n",
      "Epoch 428/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 4.1197 - val_loss: 21.9598\n",
      "Epoch 429/500\n",
      "39/39 [==============================] - 0s 113us/step - loss: 4.0878 - val_loss: 21.9628\n",
      "Epoch 430/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 4.0561 - val_loss: 21.9659\n",
      "Epoch 431/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 4.0241 - val_loss: 21.9686\n",
      "Epoch 432/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 3.9920 - val_loss: 21.9713\n",
      "Epoch 433/500\n",
      "39/39 [==============================] - 0s 93us/step - loss: 3.9613 - val_loss: 21.9739\n",
      "Epoch 434/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 3.9299 - val_loss: 21.9770\n",
      "Epoch 435/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 3.9002 - val_loss: 21.9804\n",
      "Epoch 436/500\n",
      "39/39 [==============================] - 0s 87us/step - loss: 3.8702 - val_loss: 21.9833\n",
      "Epoch 437/500\n",
      "39/39 [==============================] - 0s 113us/step - loss: 3.8391 - val_loss: 21.9857\n",
      "Epoch 438/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 3.8095 - val_loss: 21.9874\n",
      "Epoch 439/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 3.7815 - val_loss: 21.9888\n",
      "Epoch 440/500\n",
      "39/39 [==============================] - 0s 108us/step - loss: 3.7519 - val_loss: 21.9899\n",
      "Epoch 441/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 3.7235 - val_loss: 21.9912\n",
      "Epoch 442/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 3.6960 - val_loss: 21.9932\n",
      "Epoch 443/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 3.6680 - val_loss: 21.9956\n",
      "Epoch 444/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 3.6405 - val_loss: 21.9976\n",
      "Epoch 445/500\n",
      "39/39 [==============================] - 0s 107us/step - loss: 3.6134 - val_loss: 21.9994\n",
      "Epoch 446/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 3.5861 - val_loss: 22.0013\n",
      "Epoch 447/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 3.5592 - val_loss: 22.0033\n",
      "Epoch 448/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 3.5325 - val_loss: 22.0053\n",
      "Epoch 449/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 3.5051 - val_loss: 22.0079\n",
      "Epoch 450/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 3.4776 - val_loss: 22.0109\n",
      "Epoch 451/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 3.4503 - val_loss: 22.0143\n",
      "Epoch 452/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 3.4234 - val_loss: 22.0176\n",
      "Epoch 453/500\n",
      "39/39 [==============================] - 0s 88us/step - loss: 3.3966 - val_loss: 22.0202\n",
      "Epoch 454/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 3.3699 - val_loss: 22.0226\n",
      "Epoch 455/500\n",
      "39/39 [==============================] - 0s 117us/step - loss: 3.3425 - val_loss: 22.0248\n",
      "Epoch 456/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 3.3160 - val_loss: 22.0269\n",
      "Epoch 457/500\n",
      "39/39 [==============================] - 0s 109us/step - loss: 3.2886 - val_loss: 22.0290\n",
      "Epoch 458/500\n",
      "39/39 [==============================] - 0s 91us/step - loss: 3.2619 - val_loss: 22.0314\n",
      "Epoch 459/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 3.2359 - val_loss: 22.0333\n",
      "Epoch 460/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 3.2089 - val_loss: 22.0350\n",
      "Epoch 461/500\n",
      "39/39 [==============================] - 0s 109us/step - loss: 3.1826 - val_loss: 22.0366\n",
      "Epoch 462/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 3.1569 - val_loss: 22.0381\n",
      "Epoch 463/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 3.1319 - val_loss: 22.0398\n",
      "Epoch 464/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 3.1071 - val_loss: 22.0422\n",
      "Epoch 465/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 3.0837 - val_loss: 22.0447\n",
      "Epoch 466/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 3.0594 - val_loss: 22.0471\n",
      "Epoch 467/500\n",
      "39/39 [==============================] - 0s 94us/step - loss: 3.0349 - val_loss: 22.0492\n",
      "Epoch 468/500\n",
      "39/39 [==============================] - 0s 99us/step - loss: 3.0121 - val_loss: 22.0511\n",
      "Epoch 469/500\n",
      "39/39 [==============================] - 0s 95us/step - loss: 2.9887 - val_loss: 22.0527\n",
      "Epoch 470/500\n",
      "39/39 [==============================] - 0s 98us/step - loss: 2.9647 - val_loss: 22.0541\n",
      "Epoch 471/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 2.9418 - val_loss: 22.0554\n",
      "Epoch 472/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 2.9181 - val_loss: 22.0566\n",
      "Epoch 473/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 2.8956 - val_loss: 22.0578\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 99us/step - loss: 2.8724 - val_loss: 22.0590\n",
      "Epoch 475/500\n",
      "39/39 [==============================] - 0s 100us/step - loss: 2.8485 - val_loss: 22.0602\n",
      "Epoch 476/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 2.8258 - val_loss: 22.0615\n",
      "Epoch 477/500\n",
      "39/39 [==============================] - 0s 85us/step - loss: 2.8036 - val_loss: 22.0632\n",
      "Epoch 478/500\n",
      "39/39 [==============================] - 0s 90us/step - loss: 2.7802 - val_loss: 22.0646\n",
      "Epoch 479/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 2.7589 - val_loss: 22.0656\n",
      "Epoch 480/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 2.7360 - val_loss: 22.0671\n",
      "Epoch 481/500\n",
      "39/39 [==============================] - 0s 104us/step - loss: 2.7135 - val_loss: 22.0693\n",
      "Epoch 482/500\n",
      "39/39 [==============================] - 0s 84us/step - loss: 2.6928 - val_loss: 22.0720\n",
      "Epoch 483/500\n",
      "39/39 [==============================] - 0s 83us/step - loss: 2.6700 - val_loss: 22.0751\n",
      "Epoch 484/500\n",
      "39/39 [==============================] - 0s 106us/step - loss: 2.6489 - val_loss: 22.0788\n",
      "Epoch 485/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 2.6269 - val_loss: 22.0819\n",
      "Epoch 486/500\n",
      "39/39 [==============================] - 0s 89us/step - loss: 2.6050 - val_loss: 22.0846\n",
      "Epoch 487/500\n",
      "39/39 [==============================] - 0s 86us/step - loss: 2.5838 - val_loss: 22.0870\n",
      "Epoch 488/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 2.5626 - val_loss: 22.0896\n",
      "Epoch 489/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 2.5412 - val_loss: 22.0929\n",
      "Epoch 490/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 2.5213 - val_loss: 22.0962\n",
      "Epoch 491/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 2.5003 - val_loss: 22.0994\n",
      "Epoch 492/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 2.4798 - val_loss: 22.1028\n",
      "Epoch 493/500\n",
      "39/39 [==============================] - 0s 101us/step - loss: 2.4589 - val_loss: 22.1059\n",
      "Epoch 494/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 2.4390 - val_loss: 22.1094\n",
      "Epoch 495/500\n",
      "39/39 [==============================] - 0s 102us/step - loss: 2.4189 - val_loss: 22.1126\n",
      "Epoch 496/500\n",
      "39/39 [==============================] - 0s 92us/step - loss: 2.3989 - val_loss: 22.1152\n",
      "Epoch 497/500\n",
      "39/39 [==============================] - 0s 96us/step - loss: 2.3782 - val_loss: 22.1177\n",
      "Epoch 498/500\n",
      "39/39 [==============================] - 0s 81us/step - loss: 2.3586 - val_loss: 22.1205\n",
      "Epoch 499/500\n",
      "39/39 [==============================] - 0s 97us/step - loss: 2.3389 - val_loss: 22.1230\n",
      "Epoch 500/500\n",
      "39/39 [==============================] - 0s 103us/step - loss: 2.3196 - val_loss: 22.1252\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "data_input = get_model_input_data(df)\n",
    "\n",
    "history = model.fit(data_input, df.star_rating, epochs=500, verbose=1, validation_split=0.2)\n",
    "\n",
    "model.save('regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8FVX+//HXJ71SQi/BoNIRAkSki6KIKHYF14arsiqKuq7fdXe/u279bXHtuih2/QIqooKKIioILAoEpBfpElroPZByfn/cAUNI4AZyMzfJ+/l43MedOXNm7mcuYT53zsycY845RERETibC7wBERKRiUMIQEZGgKGGIiEhQlDBERCQoShgiIhIUJQwREQmKEoZIGTCzN8zsr0HWXWtmF53udkTKmxKGiIgERQlDRESCooQhVYbXFPSImS0ws/1m9qqZ1TOzz8xsr5l9aWY1C9W/wswWm9kuM5tiZq0KLetgZnO99d4F4op81uVmNs9bd4aZtTvFmO8ys5VmtsPMxptZQ6/czOwpM8s2sz1mttDM2nrL+pvZEi+2DWb2q1P6wkSKUMKQquZa4GKgOTAA+Az4LVCHwP+HYQBm1hwYDTzoLZsAfGxmMWYWA3wEvA2kAGO87eKt2wF4DfgFUAt4CRhvZrGlCdTMLgT+DtwANADWAe94i/sCvbz9qO7V2e4texX4hXMuGWgLfF2azxUpiRKGVDXPOee2OOc2ANOAmc65751zOcCHQAev3kDgU+fcJOdcLvBvIB7oBnQBooGnnXO5zrn3gdmFPmMI8JJzbqZzLt859yZwyFuvNG4CXnPOzXXOHQJ+A3Q1szQgF0gGWgLmnFvqnNvkrZcLtDazas65nc65uaX8XJFiKWFIVbOl0PTBYuaTvOmGBH7RA+CcKwDWA428ZRvcsT13ris0fQbwsNcctcvMdgGp3nqlUTSGfQTOIho5574GngdeALLNbISZVfOqXgv0B9aZ2Tdm1rWUnytSLCUMkeJtJHDgBwLXDAgc9DcAm4BGXtkRTQpNrwf+5pyrUeiV4JwbfZoxJBJo4toA4Jx71jnXCWhNoGnqEa98tnPuSqAugaaz90r5uSLFUsIQKd57wGVm1sfMooGHCTQrzQC+BfKAYWYWbWbXAJ0LrfsycLeZneddnE40s8vMLLmUMYwGbjezdO/6x/8j0IS21szO9bYfDewHcoAC7xrLTWZW3WtK2wMUnMb3IHKUEoZIMZxzy4GbgeeAbQQukA9wzh12zh0GrgEGAzsIXO/4oNC6mcBdBJqMdgIrvbqljeFL4PfAWAJnNWcBg7zF1Qgkpp0Emq22A497y24B1prZHuBuAtdCRE6baQAlEREJhs4wREQkKEoYIiISFCUMEREJihKGiIgEJcrvAMpS7dq1XVpamt9hiIhUGHPmzNnmnKsTTN1KlTDS0tLIzMz0OwwRkQrDzNadvFaAmqRERCQoIUsYZpZqZpO9bpYXm9kDXvnjZrbM62L6QzOrUcL6a70um+eZmU4bRER8FsozjDzgYedcawK9dA41s9bAJKCtc64d8AOBHjhLcoFzLt05lxHCOEVEJAghu4bhdbW8yZvea2ZLCfSy+UWhat8B14UqBoDc3FyysrLIyckJ5cdUGXFxcTRu3Jjo6Gi/QxGRclYuF729/vs7ADOLLPo58G4JqzngCzNzBMYWGHEqn52VlUVycjJpaWkc27molJZzju3bt5OVlUXTpk39DkdEylnIL3qbWRKBztMedM7tKVT+OwLNViNLWLWHc64jcCmB5qxeJWx/iJllmlnm1q1bj1uek5NDrVq1lCzKgJlRq1Ytna2JVFEhTRhe18tjgZHOuQ8KlQ8GLgduciX0fuiNiIZzLpvASGidS6g3wjmX4ZzLqFOn+FuJlSzKjr5LkaorZE1S3uAyrwJLnXNPFirvB/wPcL5z7kAJ6yYCEd61j0QC4xf/OVSxioiEBecgPxfyDkKu98rLgdwDkJtTqDwHcvfD4f1w+ABERkGPh0IeXiivYXQn0C//QjOb55X9FngWiAUmeb9Wv3PO3W1mDYFXnHP9gXrAh97yKGCUc+7zEMYaMrt27WLUqFHce++9pVqvf//+jBo1iho1ir3rWETKy5GDeO4B72B9oNDBvNCB/ei8d4DPyyly0A+mzgFwpzDeVVK9ip0wnHPTgeLaLyaUUH8jgXGIcc6tBtqHKrbytGvXLv7zn/8clzDy8vKIiir5658wodivSaRqcg7yDkH+ocB73iHIPxw4yB4zfbhInSDqH3PQ95LB4f3Hlrn80sdsERAVD9Fx3nuR6fgaEBUH0Qkl14mOL6FOfKAsJgGiEyEqpuy/82JUqq5BwtGjjz7KqlWrSE9PJzo6mri4OGrWrMmyZcv44YcfuOqqq1i/fj05OTk88MADDBkyBPipm5N9+/Zx6aWX0qNHD2bMmEGjRo0YN24c8fHxPu+ZVCrOQUF+4MBYkOe98r2XN++8+VIdnL33/EOFpg+XsM4J6uQfLpv9jIiCyNjAATYqDiJjvIOxdwCOT4Fq8ceWFT5AH1d25KDuHeijE7wDfHxg25Xsml+VShh/+ngxSzbuOX5BQV6RAit28nhG6/pJPHZZ8+PX9f5Q/vHXP7Fo0ULmzZnFlClTueyKK1k0f17gttSCPF575WVSUlI4ePAg557XhWuvuZpatWof8ykrVqxg9OjRvPzyy9xwww2MHTuWm2++OdjdllBxLvC3k58LBbmQn+e9H/bKiiw75hduoQPl0QN0oVd+MWXHvPILbTu30Hq5x74fE1eulwCKWyc3dN+TRXgHae91zLR34I5JgKgUb764ekUO8lFxx64fFePVKTxdzGdGRIZuP6uAKpUwSpR3GreJ5uTC1mUlL9++MXBQ2LIYdq6hc/vWNE3YB1sWAvDsEy/y4WeTAViftYkV306gVqd2gYPL5gWw/yBNUxuSXhfYOI9OzRqyduF3sKndT59x9FeMFZkvXFZo+oRlQfwi2pcNrz8cOGAGJch6pzJcsBlggYOSWZGyYt4tIvA5R34tu4Kf3o+W5Rc5yOYde3A+Mn3cD40QiIgO/CqOiAoc7CKLzEdEH1sWGR0oi0n4ad3IqJLrRR7ZVuG63ssivc+I+undvBiOHJij4oo5mMceOx0RVel+aVdVVSphPDagTfELcg8WOlh578ccvIIpK6HObgL/GaunQuKPJFavCdUaA44p0/7LlzPm8e2UiSTEJ9C7/9XkRCZDcoPAf9DEuuD2ExufAEl1wTki45M5uG8/JKQU//m4QsdnV+jNFTNPkXVKccC2iJOcfRWtH2zl0mzU/bT/R5pUjpad4B1+OhgefY8O7NORsiMH12MOrNGBg+AxB+Do4w/IkV69Y9aPPvbX8zEH1GIO1hFRxyZBkTBQpRJGiaJDdz0guS7s3X8AEmtDfPXAQSIp8LzI7sMR1Kxdl4S6TVm2bBnfzZ4bSATJ9QMHreT6YPsCB49qDQMbjKsOeZFQvXHIYj6prXkw+BP/Pl9EfKGEEWK1atWie/futG3blvj4eOrVq3d0Wb9+/XjxxRdp1aoVLVq0oEuXLj5GKiJyYlbCg9YVUkZGhis6gNLSpUtp1aqVTxFVTvpORSoPM5sTbI/gGkBJRESCooQhIiJBUcIQEZGgKGGIiEhQlDBERCQoShgiIhIUJYwwk5SUBMDGjRu57rrihzvv3bs3RW8fLurpp5/mwIGfhhvp378/u3btKrtARaTKUcIIUw0bNuT9998/5fWLJowJEyZobA0ROS1KGCH26KOP8sILLxyd/+Mf/8hf//pX+vTpQ8eOHTnnnHMYN27cceutXbuWtm3bAnDw4EEGDRpEq1atuPrqqzl48ODRevfccw8ZGRm0adOGxx57DIBnn32WjRs3csEFF3DBBRcAge7St23bBsCTTz5J27Ztadu2LU8//fTRz2vVqhV33XUXbdq0oW/fvsd8johIKIdoTQXeIjB6ngNGOOeeMbMU4F0gDVgL3OCc21nM+rcB/+vN/tU59+ZpB/XZo7B54Wlv5hj1z4FL/1Hi4oEDB/Lggw8ydOhQAN577z0mTpzIsGHDqFatGtu2baNLly5cccUVJY6XPXz4cBISEli6dCkLFiygY8eOR5f97W9/IyUlhfz8fPr06cOCBQsYNmwYTz75JJMnT6Z27WO7Sp8zZw6vv/46M2fOxDnHeeedx/nnn0/NmjXVjbqInFAozzDygIedc62BLsBQM2sNPAp85ZxrBnzlzR/DSyqPAecBnYHHzKxmCGMNmQ4dOpCdnc3GjRuZP38+NWvWpH79+vz2t7+lXbt2XHTRRWzYsIEtW7aUuI2pU6cePXC3a9eOdu1+6tr8vffeo2PHjnTo0IHFixezZMmSE8Yzffp0rr76ahITE0lKSuKaa65h2rRpADRt2pT09HQAOnXqxNq1a09z70WkMgnlEK2bgE3e9F4zWwo0Aq4EenvV3gSmAL8usvolwCTn3A4AM5sE9ANGn1ZQJzgTCKXrr7+e999/n82bNzNw4EBGjhzJ1q1bmTNnDtHR0aSlpZGTU/oxOdasWcO///1vZs+eTc2aNRk8ePApbeeI2NjYo9ORkZFqkhKRY5TLNQwzSwM6ADOBel4yAdhMoMmqqEbA+kLzWV5ZcdseYmaZZpa5devWMou5LA0cOJB33nmH999/n+uvv57du3dTt25doqOjmTx5MuvWrTvh+r169WLUqFEALFq0iAULFgCwZ88eEhMTqV69Olu2bOGzzz47uk5ycjJ79+49bls9e/bko48+4sCBA+zfv58PP/yQnj17luHeikhlFfLuzc0sCRgLPOic21O4nd4558zstLrLdc6NAEZAoLfa09lWqLRp04a9e/fSqFEjGjRowE033cSAAQM455xzyMjIoGXLlidc/5577uH222+nVatWtGrVik6dOgHQvn17OnToQMuWLUlNTaV79+5H1xkyZAj9+vWjYcOGTJ48+Wh5x44dGTx4MJ07dwbgzjvvpEOHDmp+EpGTCmn35mYWDXwCTHTOPemVLQd6O+c2mVkDYIpzrkWR9W706vzCm3/Jq3fCJil1b14+9J2KVB5h0b25BU4lXgWWHkkWnvHAbd70bcDx95TCRKCvmdX0Lnb39cpERMQnobyG0R24BbjQzOZ5r/7AP4CLzWwFcJE3j5llmNkrAN7F7r8As73Xn49cABcREX+E8i6p6UBJI9j3KaZ+JnBnofnXgNfKKJYSn3GQ0qlMIzSKSOlU+ie94+Li2L59uw50ZcA5x/bt24mLi/M7FBHxQcjvkvJb48aNycrKIlxvua1o4uLiaNy4sd9hiIgPKn3CiI6OpmnTpn6HISJS4VX6JikRESkbShgiIhIUJQwREQlKpb+GEYxnv1pBhEF8TBQJMZEkxEQSHx1JYmwU8d58QvRP0/HRkURE6DZdEalalDCAl75Zxf7D+aVaJy46gsSYQBJJjImiekI0KQkx1EyMoVbiT+91q8XSsHo89avHERcdGaI9EBEJPSUMYPGf+3E4r4CDh/M5kJvHgcP5genD+Rw4nOe953Ow8HSut+xQPvsP57HrQC6rt+1jx7rD7DyQS37B8c991E6KoUH1eBpUj+OMWgmcVSeJs+omcWbtRFISY/RwoYiENSUMT0xUBDFREVQn+rS3VVDg2JOTy/b9h9myO4eNu3PYtOtg4H33QdZu3883P2zlUF7B0XVqJERzZu1EWtSvRpuG1WjbqDot6yfrrEREwoYSRghERBg1EmKokRDDWXWSiq1TUODYsOsgq7buY9XW/azeuo+V2fuYsHATo2f9CEBkhNGsbhLpqTU4Ny2Fc9NSSE2J15mIiPhCCcMnERFGakoCqSkJ9C7UubtzjqydB1m8cTeLNuxh4YbdTFi4iXdmB8aTqlctloy0FHqcXZveLerQoHq8T3sgIlWNEkaYMfspkfRr2wAInI38kL2X2Wt3krl2B7PW7ODTBYFBC1vUS+b8FnXo3bwOGWkpxETpTmkRCY2QDqBU3oobQKkycs6xMnsfU5ZvZcoP2cxas4PcfEdiTCTnt6jDpW0bcGHLuiTG6veAiJxYaQZQUsKoBPYfymPGqu1MXp7NpCVb2Lr3ELFREZzfvA79z2nAha3qUi3u9C/mi0jlo4RRheUXOOas28mEhZv4fNFmNu/JISYqgr6t63F9Rio9zq5NpB46FBFPWCQMM3sNuBzIds619creBY5c4q0B7HLOpRez7lpgL5AP5AW7M0oYxyoocHy/fhfj521g3PyN7DqQS71qsVzTsTHXdWpc4h1cIlJ1hEvC6AXsA946kjCKLH8C2O2c+3Mxy9YCGc65baX5TCWMkh3Ky+frpdmMmZPFNz9sJb/A0bFJDW7pegb9z2lAbJSe9xCpisIiYXiBpAGfFE0YFniQ4EfgQufcimLWW4sSRshk78nho3kbeGfWelZv20/tpFh+1jmVm7qcQb1qGk1PpCqpCAmjF/BkSUGa2RpgJ+CAl5xzI07wGUOAIQBNmjTptG7durIJvgooKHBMW7mNN2esZfLybCLN6Ne2PoO7pdHpjJp6QFCkCqgICWM4sNI590QJ6zVyzm0ws7rAJOB+59zUk32ezjBO3brt+3nr23W8l7mevTl5tGlYjcHd0rgyvZGe7RCpxMI6YZhZFLAB6OScywpiG38E9jnn/n2yukoYp2//oTw+/H4Db327lh+27KNh9TiG9DqTQZ2bqF8rkUqoNAnDj5+OFwHLSkoWZpZoZslHpoG+wKJyjK9KS4yN4uYuZzDxwV68cfu5NKoZzx8/XkKPf37N8Cmr2Hcoz+8QRcQnIUsYZjYa+BZoYWZZZnaHt2gQMLpI3YZmNsGbrQdMN7P5wCzgU+fc56GKU4pnZvRuUZcxd3fj3SFdaNWgGv/8fBm9/jWZV6atJie3dOOHiEjFpwf3JGjf/7iTJ774gekrt1GvWiz3XdiMgRmpusYhUoGFzTWM8qaEUT6+XbWdJ75YTua6nTSuGc9DFzXn6g6NNGytSAUU7tcwpILrelYtxtzdlTduP5eaCTE8PGY+A56fzoxVpXpsRkQqGCUMOSVHrnGMG9qdZwals+tALj97eSZ3vjmbldn7/A5PREJACUNOS0SEcWV6I756+Hx+3a8lM1fv4JKnp/L7jxaxfd8hv8MTkTKkhCFlIi46knt6n8WUR3rzs85NGDXrR3o/PoWXp64mN7/g5BsQkbCnhCFlqlZSLH+5qi0TH+zFuU1T+NuEpfR/Zpqub4hUAkoYEhJn103itcHn8sqtGeTk5fOzl2dy/+jv2bw7x+/QROQUKWFISF3Uuh6THjqfB/o0Y+LizfR5Ygojpq5SM5VIBaSEISEXFx3JQxc3Z9JDvehyZi3+34RlDHhuOvPX7/I7NBEpBSUMKTdn1Erk1cHnMuKWTuw8cJir//Nf/j5hqboZEakglDCk3PVtU58vHjqfgeem8tLU1fR7eiozV2/3OywROQklDPFF9fho/n5NO0bdeR75zjFwxHf870cL2ZuT63doIlICJQzxVbezazPxwV78vHtTRs78kUuemsrk5dl+hyUixVDCEN8lxETxhwGtGXtPNxJio7j99dn88t157Nx/2O/QRKQQJQwJGx2b1OTTYT24/8KzGT9/Ixc/9Q0TFm7yOywR8ShhSFiJjYrk4b4tGH9fD+pXj+PekXO5++05ZO/RA38ifgvliHuvmVm2mS0qVPZHM9tgZvO8V/8S1u1nZsvNbKWZPRqqGCV8tW5YjY/u7c6v+7Xk6+XZXPTkN4zJXE9lGr9FpKIJ5RnGG0C/Ysqfcs6le68JRReaWSTwAnAp0Bq40cxahzBOCVNRkRHc0/ssPnugJy3qJ/PI+wu47fXZZO084HdoIlVSyBKGc24qsOMUVu0MrHTOrXbOHQbeAa4s0+CkQjmrThLvDunKn69sQ+baHfR9aiojZ67T2YZIOfPjGsZ9ZrbAa7KqWczyRsD6QvNZXlmxzGyImWWaWebWrVvLOlYJExERxq1d0/jioV50bFKT3324iDvfzGSbxtwQKTflnTCGA2cB6cAm4InT3aBzboRzLsM5l1GnTp3T3ZyEucY1E3jr5535w+WtmbZyG/2enspXS7f4HZZIlVCuCcM5t8U5l++cKwBeJtD8VNQGILXQfGOvTAQInG38vEdTPr6vB3WS47jjzUx+++FCDhzO8zs0kUqtXBOGmTUoNHs1sKiYarOBZmbW1MxigEHA+PKITyqWFvWT+WhoN37R60xGz/qRy56dzoIs9YArEiqhvK12NPAt0MLMsszsDuBfZrbQzBYAFwAPeXUbmtkEAOdcHnAfMBFYCrznnFscqjilYouNiuQ3/Vsx6s4uHMrN59rhM3hl2mpdEBcJAatM/7EyMjJcZmam32GIT3YdOMwj7y9g0pIt9GlZl39f356aiTF+hyUS1sxsjnMuI5i6etJbKo0aCTGMuKUTfxzQmmkrttH/2WnMWnMqd3aLSHGUMKRSMTMGd2/KB/d2IzYqgkEjvuW5r1aQX1B5zqRF/KKEIZVS20bV+WRYTwa0b8gTk37g1tdmkr1X/VGJnA4lDKm0kmKjeHpgOv+6th1z1u2k/zPTmLZCD3eKnColDKnUzIwbzk1l/H09SEmM4dbXZvGvz5eRl1/gd2giFY4ShlQJzeslM25oDwadm8p/pqxi4Ijv2LDroN9hiVQoShhSZcTHRPL3a9rx7I0dWL55L/2fmcYXizf7HZZIhaGEIVXOFe0b8sn9PUhNiWfI23P44/jFHMrL9zsskbCnhCFVUlrtRMbe043bu6fxxoy1XDt8Bmu37fc7LJGwpoQhVVZsVCSPDWjDy7dmsH7HQS5/bjrj5qmfS5GSKGFIlXdx63pMeKAnLesn88A783h07AIOHlYTlUhRShgiQKMa8bwzpAtDLziLdzPXc+UL01mxZa/fYYmEFSUMEU9UZASPXNKSt37emR37D3PF8//lw++z/A5LJGwoYYgU0bNZHSYM68k5javz0Lvz+c0HC8nJVROViBKGSDHqVotj1J3ncff5ZzF61o9cO3wG67brLiqp2pQwREoQFRnBo5e25NXbMsjaGbiLaqIe9JMqLKiEYWYPmFk1C3jVzOaaWd+TrPOamWWb2aJCZY+b2TIzW2BmH5pZjRLWXeuNzDfPzDQikviqT6t6fHJ/D5rWTuQXb8/hb58uIVd9UUkVFOwZxs+dc3uAvkBN4BbgHydZ5w2gX5GySUBb51w74AfgNydY/wLnXHqwI0GJhFJqSgJj7u7KrV3P4OVpa7j11Vns2H/Y77BEylWwCcO89/7A294Y23aC+jjnpgI7ipR94Y3ZDfAd0LgUsYr4KjYqkj9f2ZYnrm/PnB93csXz01mycY/fYYmUm2ATxhwz+4JAwphoZsnA6Z6T/xz4rIRlDvjCzOaY2ZATbcTMhphZppllbt2qsQ4k9K7t1Jgxv+hKXr7j2uEz+GTBRr9DEikXwSaMO4BHgXOdcweAaOD2U/1QM/sdkAeMLKFKD+dcR+BSYKiZ9SppW865Ec65DOdcRp06dU41JJFSaZ9ag/H3d6d1w2rcN+p7/vX5Mg0DK5VesAmjK7DcObfLzG4G/hfYfSofaGaDgcuBm5xzxf4Pc85t8N6zgQ+BzqfyWSKhVDc5jlF3nceNnQNjbNz55mz25OT6HZZIyASbMIYDB8ysPfAwsAp4q7QfZmb9gP8BrvDOVIqrk+g1eWFmiQQutC8qrq6I32KjAmNs/PWqtkxbsY2rnv8vK7P3+R2WSEgEmzDyvLOBK4HnnXMvAMknWsHMRgPfAi3MLMvM7gCe99ab5N0y+6JXt6GZTfBWrQdMN7P5wCzgU+fc56XeM5FydHOXMxh553nsPpjL1S/8l6+WbvE7JJEyZyW0Ch1byewb4HMCF6p7AtnAfOfcOaENr3QyMjJcZqYe2xD/bNx1kCFvZ7J44x4evrg5Qy84G7MT3lAo4iszmxPs4wvBnmEMBA4ReB5jM4HbYR8/xfhEKq2GNeJ5/+5uXNm+If/+4geGjprL/kN5J19RpAIIKmF4SWIkUN3MLgdynHOlvoYhUhXERUfy1MB0fte/FZ8v2sy1w2ewfkexl+xEKpRguwa5gcD1hOuBG4CZZnZdKAMTqcjMjLt6nckbt3dm466DDHh+Ov9duc3vsEROS7BNUr8j8AzGbc65Wwnc5vr70IUlUjn0al6H8ff1oG5yLLe+NotXp68hmOuGIuEo2IQR4T0TccT2UqwrUqWl1U7kg3u706dlXf7yyRJ+NWaBxteQCinYg/7nZjbRzAZ7D959Ckw4yToi4kmKjeLFmzvx4EXNGDs3i4Evfcum3Qf9DkukVIK96P0IMAJo571GOOd+HcrARCqbiAjjwYuaM+KWTqzM3seA56Yza82Ok68oEiaCeg6jotBzGFJRrNiylyFvz2H9jgM8NqA1N3c5Q89riC/K7DkMM9trZnuKee01M/XrLHKKmtVL5qOh3enVvA6/H7eYX4/VdQ0JfydMGM65ZOdctWJeyc65auUVpEhlVD0+mlduzWDYhWfzXmYWA0d8x+bdOX6HJVIi3ekk4qOICOOXfVvw4s2dWLllL5c/N53Za3VdQ8KTEoZIGOjXtj4fDe1OclwUN474jre/XavnNSTsKGGIhAld15Bwp4QhEkaOu67x0rds3KXnNSQ8KGGIhJkj1zVeuqUTq7buZ8Bz0/l21Xa/wxJRwhAJV5e0CVzXqJ4Qzc2vzuSVaat1XUN8FdKEYWavmVm2mS0qVJZiZpPMbIX3XrOEdW/z6qwws9tCGadIuDq7bhLjhgb6ofrrp0t54J15HDis8TXEH6E+w3gD6Fek7FHgK+dcM+Arb/4YZpYCPAacR6Bn3MdKSiwilV1yXDQv3tyJRy5pwccLNnL1CzNYs22/32FJFRTShOGcmwoUvan8SuBNb/pN4KpiVr0EmOSc2+Gc2wlM4vjEI1JlREQYQy84mzdv70z23hyueG46Xyze7HdYUsX4cQ2jnnNukze9GahXTJ1GwPpC81le2XHMbIiZZZpZ5tatW8s2UpEw06t5HT6+vwdptRMZ8vYcHp+4jPwCXdeQ8uHrRW8XuIJ3Wn/tzrkRzrkM51wKwnMZAAASoklEQVRGnTp1yigykfDVuGYCY+7uysCMVF6YvIrBr89i5/7DfoclVYAfCWOLmTUA8N6zi6mzAUgtNN/YKxMRAuOG//O6dvzjmnOYuXoHlz83nYVZu/0OSyo5PxLGeODIXU+3AeOKqTMR6GtmNb2L3X29MhEpZFDnJoy5uysA1744g3dn/+hzRFKZhfq22tHAt0ALM8syszuAfwAXm9kK4CJvHjPLMLNXAJxzO4C/ALO915+9MhEpon1qDT6+vwed01L49diFPKouRSRENICSSCWRX+B44ovl/GfKKto0rMbwmzrRpFaC32FJmCuzAZREpOKIjDD+p19LXrk1g/U7DnDZc9N0662UKSUMkUrmotb1+HRYT9JqBW69/fuEpeTlF/gdllQCShgilVBqSuDW25vOa8JLU1fzs5dnsmWPRvOT06OEIVJJxUVH8rerz+Hpgeks3LCby56dxoxV2/wOSyowJQyRSu6qDo0Yf193qsdHc/MrM3lh8koK9HS4nAIlDJEqoFm9ZMbf14PL2jXk8YnLuePN2Xo6XEpNCUOkikiMjeLZQen85co2TF+5jcufm87cH3f6HZZUIEoYIlWImXFL1zTev7sbZnDDi99qYCYJmhKGSBXUPrUGn97fkwu9gZmGvD2H3Qdy/Q5LwpwShkgVVT0hmpdu6cQfLm/NlOXZ9H92GvPW7/I7LAljShgiVZiZ8fMeTRlzdzcArhs+Q01UUiIlDBEhPbUGE4b15AKviequt+aw64DuopJjKWGICBBoohrhNVF980M2lz2ru6jkWEoYInLUkSYq3UUlxVHCEJHjtE+twafDenJRq3peE1WmmqhECUNEilc9PprhN3fkjwNaM/WHbfR/ZhqZazWOWVVW7gnDzFqY2bxCrz1m9mCROr3NbHehOn8o7zhFJNBENbh7U8be042oyAhueOlbnv7yB3WXXkVFlfcHOueWA+kAZhYJbAA+LKbqNOfc5eUZm4gU75zG1fl0WA8eG7+Yp79cwfQV23h6UDqNa2pEv6rE7yapPsAq59w6n+MQkZNIjovmyRvSeWZQOss37+XSZ6bx8fyNfocl5cjvhDEIGF3Csq5mNt/MPjOzNiVtwMyGmFmmmWVu3bo1NFGKyFFXpjdiwgM9ObtuEveP/p5fjZnPvkN5focl5cD8ul3OzGKAjUAb59yWIsuqAQXOuX1m1h94xjnX7GTbzMjIcJmZmaEJWESOkZdfwLNfreD5yStpkpLAM4M60D61ht9hSSmZ2RznXEYwdf08w7gUmFs0WQA45/Y45/Z50xOAaDOrXd4BikjJoiIj+GXfFoy+qwuH8wq4dvgMhk9ZpcGZKjE/E8aNlNAcZWb1zcy86c4E4txejrGJSJDOO7MWnz3Qi75t6vHPz5dx48vfsX7HAb/DkhDwJWGYWSJwMfBBobK7zexub/Y6YJGZzQeeBQY5PWoqEraqJ0Tzws868q/r2rF44x4ufWYa787+UU+IVzK+XcMIBV3DEPFf1s4D/GrMfL5bvYM+Levy92vPoW5ynN9hSQkqyjUMEamEGtdMYNSdXfjD5a2ZvnIblzw1lU8XbPI7LCkDShgiUuYiIgKdGH46rCdNUhIYOmou942ay4796o+qIlPCEJGQObtuEmPv6cYjl7Rg4uLN9H3qGz5ftNnvsOQUKWGISEhFRUYw9IKzGX9fD+pVi+Pu/5vDg+98r95vKyAlDBEpF60aVOOjod156KLmfLJgExc/NZVJS457DEvCmBKGiJSb6MgIHrioGePu606txBjueiuTX743j90Hcv0OTYKghCEi5a5Nw+qMv68Hwy48m3HzNtL36W+YvCzb77DkJJQwRMQXMVGBrkU+urc7NeJjuP2N2TwyZj57cnS2Ea6UMETEV+c0rs74+7sz9IKzGDs3i0uemsqU5TrbCEdKGCLiu9ioSB65pCUf3NudxNgoBr8+m4fenafnNsKMEoaIhI301Bp8OqwHw/o045MFG7noyW8YN2+D+qQKE0oYIhJWYqMi+eXFzfnk/sBT4g+8M4/b35hN1k71gOs3JQwRCUst6icz9p5uPDagNbPW7KDvU1N5/b9ryNd4G75RwhCRsBUZYdzevSlfPNSLc9NS+NPHS7juxRn8sGWv36FVSUoYIhL2GtdM4I3bz+Xpgems3bafy56dxhNfLOfg4Xy/Q6tSlDBEpEIwM67q0Igvf3k+l7dryHNfr6TPE1P4dMEmXRQvJ74lDDNba2YLzWyemR036pEFPGtmK81sgZl19CNOEQkvtZJieWpgOu8O6UK1+GiGjprLz16eyfLNaqYKNb/PMC5wzqWXMNrTpUAz7zUEGF6ukYlIWDvvzFp8cn8P/nJVW5Zu3sOlz0zlNx8sYMueHL9Dq7T8ThgnciXwlgv4DqhhZg38DkpEwkdUZAS3dDmDyQ/35rZuabw/J4vej0/hiS+Ws1ddjJQ5PxOGA74wszlmNqSY5Y2A9YXms7yyY5jZEDPLNLPMrVu3hihUEQlnNRNjeGxAG7785fn0aVWX575eSe/Hp/DWt2vJzS/wO7xKw8+E0cM515FA09NQM+t1Khtxzo1wzmU45zLq1KlTthGKSIVyRq1Env9ZR8YN7c7ZdZP4w7jF9H1qKhMW6sJ4WfAtYTjnNnjv2cCHQOciVTYAqYXmG3tlIiIn1D61Bu8M6cJrgzOIjjTuHTmXa4bPYNaaHX6HVqH5kjDMLNHMko9MA32BRUWqjQdu9e6W6gLsds5tKudQRaSCMjMubFmPzx7oxb+ubcfGXQe54aVvueutTFZm646qUxHl0+fWAz40syMxjHLOfW5mdwM4514EJgD9gZXAAeB2n2IVkQosMsK44dxUBrRvyGv/XcPwKavo+9RUBp7bhIcuakbdanF+h1hhWGVq18vIyHCZmcc90iEictT2fYd47uuVjJy5jqiICO7qdSZDep1JUqxfv5/9ZWZzSni04fi6ShgiUhWt276fxycu55MFm6idFMMDfZoxqHMToiPD+WmDsleahFG1vhkREc+RO6o+Gtqds+ok8XvvjqrPdEdViZQwRKRKSy9yR9U93h1V363e7ndoYUcJQ0SqvOLuqBo04jtuHPEdM5U4jtI1DBGRInJy8xk180eGf7OKrXsP0fXMWjx4UTPOO7OW36GVOV30FhEpAzm5+Yyc+SPDp6xi275DdDurFvddeDZdz6yF91hAhaeEISJShg4ezmfUrJ8SR7vG1RnS60z6talPVAW/q0oJQ0QkBHJy8xk7N4tXpq1hzbb9pKbEc0f3plyXkVphn+NQwhARCaH8AsekJVsYMXUVc3/cRXJsFNdnpHJbtzM4o1ai3+GVihKGiEg5+f7HnbwxYy2fLthEvnNc2KIut3dvSvezK8Z1DiUMEZFytmVPDiNn/siomevYtu8wzeomMbh7Gld3aERCTPg2VylhiIj45FBePp/M38TrM9awaMMeqsVFMahzE27pcgapKQl+h3ccJQwREZ8555izbievz1jL54s245zj4tb1GNytKV3OTAmb5qrSJIzwPU8SEanAzIyMtBQy0lLYtPsg//fdOkbN/JGJi7eQViuB6zNSubZjY+pXrzjdq+sMQ0SknOTk5vPpgk2MmbOe71bvIMKgV/M63JCRSp9WdYmNiiz3mNQkJSIS5tZt38/7c7J4f04Wm3bnUDMhmsvaNeDK9EZ0alKTiIjyabIK64RhZqnAWwRG3XPACOfcM0Xq9AbGAWu8og+cc38+2baVMESkoskvcExfuY0xmev5cukWcnILaFQjngHtG3JlekNa1k8O6fWOcE8YDYAGzrm53rjec4CrnHNLCtXpDfzKOXd5abathCEiFdm+Q3lMWrKZ8fM2MnXFNvILHM3rJXFleiOuaN8wJHdZhfVFb+fcJmCTN73XzJYCjYAlJ1xRRKSSS4qN4uoOjbm6Q2O27zvEhEWbGT9vA49PXM7jE5fTsUkNrkxvxGXtGlA7Kbbc4/P1GoaZpQFTgbbOuT2FynsDY4EsYCOBs43FJWxjCDAEoEmTJp3WrVsX2qBFRMpZ1s4DfDx/E+PmbWDZ5r1EGHQ5sxaXtq3PJW3qU7faqd9pFdZNUkc/2CwJ+Ab4m3PugyLLqgEFzrl9ZtYfeMY51+xk21STlIhUdss37+Xj+RuZsGgTq7fuxwzOTUth5J3nndJ45GHdJAVgZtEEziBGFk0WAIXPNpxzE8zsP2ZW2zm3rTzjFBEJNy3qJ9Oifgse7tucFdn7+GzhZjbtPnhKyaK0yj1hWOBy/6vAUufckyXUqQ9scc45M+tMYChZjZMoIuIxM5rXS6Z5veRy+0w/zjC6A7cAC81snlf2W6AJgHPuReA64B4zywMOAoNcZXpgRESkAvLjLqnpwAlvKnbOPQ88Xz4RiYhIMCr22IIiIlJulDBERCQoShgiIhIUJQwREQmKEoaIiARFCUNERIJSqcbDMLOtwKl2JlUbqGpPkmufqwbtc9Vwqvt8hnOuTjAVK1XCOB1mlhlsfyqVhfa5atA+Vw3lsc9qkhIRkaAoYYiISFCUMH4ywu8AfKB9rhq0z1VDyPdZ1zBERCQoOsMQEZGgKGGIiEhQqnzCMLN+ZrbczFaa2aN+x1NWzOw1M8s2s0WFylLMbJKZrfDea3rlZmbPet/BAjPr6F/kp87MUs1sspktMbPFZvaAV15p99vM4sxslpnN9/b5T155UzOb6e3bu2YW45XHevMrveVpfsZ/Osws0sy+N7NPvPlKvc9mttbMFprZPDPL9MrK9W+7SicMM4sEXgAuBVoDN5pZa3+jKjNvAP2KlD0KfOWNj/6VNw+B/W/mvYYAw8spxrKWBzzsnGsNdAGGev+elXm/DwEXOufaA+lAPzPrAvwTeMo5dzawE7jDq38HsNMrf8qrV1E9ACwtNF8V9vkC51x6oectyvdv2zlXZV9AV2BiofnfAL/xO64y3L80YFGh+eVAA2+6AbDcm34JuLG4ehX5BYwDLq4q+w0kAHOB8wg88RvllR/9OwcmAl296Sivnvkd+ynsa2MCB8gLgU8IDMpW2fd5LVC7SFm5/m1X6TMMoBGwvtB8lldWWdVzzm3ypjcD9bzpSvc9eM0OHYCZVPL99ppm5gHZwCRgFbDLOZfnVSm8X0f32Vu+G6hVvhGXiaeB/wEKvPlaVP59dsAXZjbHzIZ4ZeX6t+3HmN4SBpxzzswq5T3VZpYEjAUedM7tMftpRODKuN/OuXwg3cxqAB8CLX0OKaTM7HIg2zk3x8x6+x1POerhnNtgZnWBSWa2rPDC8vjbrupnGBuA1ELzjb2yymqLmTUA8N6zvfJK8z2YWTSBZDHSOfeBV1zp9xvAObcLmEygOaaGmR35QVh4v47us7e8OrC9nEM9Xd2BK8xsLfAOgWapZ6jc+4xzboP3nk3gh0Fnyvlvu6onjNlAM+/uihhgEDDe55hCaTxwmzd9G4E2/iPlt3p3VnQBdhc6za0wLHAq8Sqw1Dn3ZKFFlXa/zayOd2aBmcUTuGazlEDiuM6rVnSfj3wX1wFfO6+Ru6Jwzv3GOdfYOZdG4P/s1865m6jE+2xmiWaWfGQa6Assorz/tv2+kOP3C+gP/ECg3fd3fsdThvs1GtgE5BJov7yDQLvtV8AK4EsgxatrBO4WWwUsBDL8jv8U97kHgXbeBcA879W/Mu830A743tvnRcAfvPIzgVnASmAMEOuVx3nzK73lZ/q9D6e5/72BTyr7Pnv7Nt97LT5yrCrvv211DSIiIkGp6k1SIiISJCUMEREJihKGiIgERQlDRESCooQhIiJBUcIQCQNm1vtIr6si4UoJQ0REgqKEIVIKZnazN/7EPDN7yev4b5+ZPeWNR/GVmdXx6qab2XfeeAQfFhqr4Gwz+9Ibw2KumZ3lbT7JzN43s2VmNtIKd4IlEgaUMESCZGatgIFAd+dcOpAP3AQkApnOuTbAN8Bj3ipvAb92zrUj8LTtkfKRwAsuMIZFNwJP5EOgd90HCYzNciaBPpNEwoZ6qxUJXh+gEzDb+/EfT6CztwLgXa/O/wEfmFl1oIZz7huv/E1gjNcfUCPn3IcAzrkcAG97s5xzWd78PALjmUwP/W6JBEcJQyR4BrzpnPvNMYVmvy9S71T72zlUaDof/f+UMKMmKZHgfQVc541HcGQ85TMI/D860kvqz4DpzrndwE4z6+mV3wJ845zbC2SZ2VXeNmLNLKFc90LkFOkXjEiQnHNLzOx/CYx6FkGgJ+ChwH6gs7csm8B1Dgh0N/2ilxBWA7d75bcAL5nZn71tXF+OuyFyytRbrchpMrN9zrkkv+MQCTU1SYmISFB0hiEiIkHRGYaIiARFCUNERIKihCEiIkFRwhARkaAoYYiISFD+PxqnHbEUvRvEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
